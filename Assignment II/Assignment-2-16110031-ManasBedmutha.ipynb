{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Generation \n",
    "\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./trump_speeches.txt\") as f:\n",
    "    data = f.read()\n",
    "    data = data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sentences = re.sub(r\"[^a-zA-Z0-9. ]+\", \" \", data)\n",
    "#sentences = re.sub(r\"...\",\".\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and padding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokens = sent_tokenize(sentences)\n",
    "word_tokens = word_tokenize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sent_tokens)):\n",
    "    sent_tokens[i] = \"<s> \" + sent_tokens[i] + \" </s>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data for easier use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test, _, _ = train_test_split(sent_tokens, range(len(sent_tokens)),test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<s> i have many  many executives upstairs and in different buildings that i have that are women. </s>',\n",
       "  '<s> and now  to top it off  we have isis. </s>',\n",
       "  '<s> it doesn t have to be this way. </s>',\n",
       "  '<s> we don t win anymore. </s>',\n",
       "  '<s> but to chart our path forward  we must first briefly take a look back. </s>',\n",
       "  '<s> that s the end of it. </s>',\n",
       "  '<s> i don t know. </s>',\n",
       "  '<s> you see him. </s>',\n",
       "  '<s> they think it s  2.5 trillion. </s>',\n",
       "  '<s> i don t want to do. </s>'],\n",
       " ['<s> it s not a friend even to the united states of america  where as you know  it has its home. </s>',\n",
       "  '<s> and i watched the next door neighbor saying   oh  well we didn t report them because we didn t want to racially profile or we didn t want to profile. </s>',\n",
       "  '<s> he understand. </s>',\n",
       "  '<s> but  you know  i started and i started at like 2  or 3  and then it went to 6  and then it went to 9 . </s>',\n",
       "  '<s> he ll never make it. </s>',\n",
       "  '<s> and people knew that they were radicalized and people in the area knew that they had bombs   who the hell doesn t know  you re their next door neighbor. </s>',\n",
       "  '<s> and it has to happen immediately. </s>',\n",
       "  '<s> everybody knows it s a horrible deal. </s>',\n",
       "  '<s> it s almost like  i don t even know. </s>',\n",
       "  '<s> one of the most sought after projects in the history of the gsa   general services. </s>'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:10], test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict choice wrt multinomial distribution\n",
    "\n",
    "def predict(str, N, freq_count):\n",
    "    pvals=[]\n",
    "    words=[]\n",
    "    seq = ' '.join(str.split()[-(N-1):])\n",
    "    if N!=1:\n",
    "        choices = freq_count[seq].items()\n",
    "    else:\n",
    "        choices = freq_count[''].items()\n",
    "\n",
    "    total = sum(weight for choice, weight in choices)\n",
    "    \n",
    "    for key,values in choices:\n",
    "        words.append(key)\n",
    "        pvals.append(values/total)\n",
    "        \n",
    "    distribution = np.random.multinomial(1, pvals)\n",
    "    idx = np.argmax(distribution)\n",
    "    choice = words[idx]\n",
    "    \n",
    "    return choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distribution of ngrams to return frequecny distribution\n",
    "\n",
    "def ngrams(lines, N):\n",
    "\n",
    "    ngrams = []\n",
    "    freq_count = {}\n",
    "#     print sentences[:10]\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        for i in range(len(tokens)-N+1):\n",
    "            ngrams.append(tokens[i:i+N])  \n",
    "    \n",
    "    for i in ngrams:\n",
    "        seq  = ' '.join(i[:-1])\n",
    "        last = str(i[-1])\n",
    "\n",
    "        if seq not in freq_count:\n",
    "            freq_count[seq] = {};\n",
    "        \n",
    "        if last not in freq_count[seq]:\n",
    "            freq_count[seq][last] = 0;\n",
    "\n",
    "        freq_count[seq][last] += 1;\n",
    "        \n",
    "    return freq_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We will do smoothing to some contsant value which is smalles in perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing\n",
    "def smoothing(perp, c):\n",
    "    for i in range(len(perp)):\n",
    "        if perp[i]==1:\n",
    "            perp[i]= c\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine Perplexity based on N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerpMat(N):\n",
    "    perp = []\n",
    "    freq = ngrams(test, N)\n",
    "    \n",
    "    for sent in test:\n",
    "        n_grams = []\n",
    "        tokens = sent.split()\n",
    "\n",
    "        for i in range(len(tokens)-N+1):\n",
    "            n_grams.append(tokens[i:i+N])\n",
    "\n",
    "        for ngram in n_grams:\n",
    "            seq  = ' '.join(ngram[:-1])\n",
    "            last = str(ngram[-1])\n",
    "\n",
    "            if seq not in freq:\n",
    "                perp.append(1.0)\n",
    "\n",
    "            elif last not in freq[seq]:\n",
    "                perp.append(1.0)\n",
    "\n",
    "            else:\n",
    "                if N!=1:\n",
    "                    choices = freq[seq].items()\n",
    "                else:\n",
    "                    choices = freq[''].items()\n",
    "\n",
    "                pvals=[]\n",
    "                key_words=[]\n",
    "                total = sum(weight for choice, weight in choices)\n",
    "                perp.append(freq[seq][last]*1.0/total)\n",
    "    \n",
    "    c = min(perp)\n",
    "    perp = smoothing(perp,c)\n",
    "\n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining counts for each MLE\n",
    "General study of counts - unigrams, bigram, trigram, quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40921, 37927, 34933, 31939)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PerpMat(1)), len(PerpMat(2)), len(PerpMat(3)), len(PerpMat(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Perplexity for', 2, 'gram: ', 47.409962590543735)\n",
      "('Perplexity for', 3, 'gram: ', 38.14224260140589)\n",
      "('Perplexity for', 4, 'gram: ', 64.04565812702502)\n"
     ]
    }
   ],
   "source": [
    "for N in range(2,5):\n",
    "    perp = PerpMat(N)\n",
    "    log_perp = abs(np.log(perp))\n",
    "    log_perp = sum(log_perp)/len(perp)\n",
    "    perplexity = np.exp(log_perp)\n",
    "    print(\"Perplexity for\",N,\"gram: \",perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sequence of words from MLE model\n",
    "# Eg. Inputs: N=2 (bigram), freq_count is got from ngrams()\n",
    "\n",
    "def generator(N, freq_count):\n",
    "    start_seq = None\n",
    "    taglist = []\n",
    "    \n",
    "    for i in freq_count.keys():\n",
    "        a = i.split()\n",
    "        if N!=1 and a[0]==\"<s>\":\n",
    "            taglist.append(i)\n",
    "    \n",
    "    if(start_seq == None) and N!=1: \n",
    "        start_seq = random.choice(taglist)\n",
    "    elif(start_seq == None) and N==1:\n",
    "        start_seq=\"<s>\"\n",
    "    out = start_seq.lower()\n",
    "    \n",
    "    next_word = \"\"\n",
    "    \n",
    "    while next_word!= \"</s>\":\n",
    "        next_word = predict(out, N, freq_count)\n",
    "        out += ' ' + next_word\n",
    "        \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Generated sentences with model complexity  ', '2')\n",
      "<s> once he left out. </s>\n",
      "<s> once he left out. </s>\n",
      "<s> once he left out. </s>\n",
      "<s> once he left out. </s>\n",
      "<s> once he left out. </s>\n",
      "('Generated sentences with model complexity  ', '3')\n",
      "<s> number one problem is he intelligent then i mean bernie sanders gave her a second class citizen will ever change. </s>\n",
      "<s> 38 to 12. that s having a celebration. </s>\n",
      "<s> oh my brother was such that i mean bernie sanders gave her a second class citizen will ever change. </s>\n",
      "<s> frankly when i first came in second. </s>\n",
      "<s> houdini couldn t care they re strong. </s>\n",
      "('Generated sentences with model complexity  ', '4')\n",
      "<s> i will. </s>\n",
      "<s> now with that being said the small money comes in and it s disgraceful. </s>\n",
      "<s> there were many times that. </s>\n",
      "<s> the list of humiliations go on and on and on. </s>\n",
      "<s> so go back. </s>\n"
     ]
    }
   ],
   "source": [
    "for N in range(2,5):\n",
    "    print(\"Generated sentences with model complexity  \",str(N))\n",
    "    freq = ngrams(train, N)\n",
    "    print(generator(N, freq))\n",
    "    print(generator(N, freq))\n",
    "    print(generator(N, freq))\n",
    "    print(generator(N, freq))\n",
    "    print(generator(N, freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./trump_speeches.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "    \n",
    "data=data.lower()\n",
    "x = re.split(r'(\\.|,)', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-04bc72770df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtot_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "final_data=[]\n",
    "for i in x:\n",
    "    if(i not in [\",\", \".\", \" \"]):\n",
    "        final_data.append(i.strip())\n",
    "\n",
    "train_data=final_data[:13500]\n",
    "test_data=final_data[13500:]\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(final_data)\n",
    "tot_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n",
    "input_sequences = []\n",
    "for i in train_data:\n",
    "    token_list = tokenizer.texts_to_sequences([i])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "        \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences,   \n",
    "                          maxlen=15, padding='pre'))\n",
    "\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "label = utils.to_categorical(label, num_classes=tot_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, max_sequence_len, model):\n",
    "    for j in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen= \n",
    "                             max_sequence_len-1, padding='pre')\n",
    "        predicted = model.predict_classes(token_list, verbose=0)\n",
    "  \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 02:20:05.555737 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1007 02:20:05.831521 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1007 02:20:05.866033 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1007 02:20:06.197400 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1007 02:20:06.205856 140346571187968 deprecation.py:506] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W1007 02:20:06.246042 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1007 02:20:06.278255 140346571187968 deprecation_wrapper.py:119] From /home/manas/.local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 14, 100)           619800    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 300)               120300    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6198)              1865598   \n",
      "=================================================================\n",
      "Total params: 2,605,698\n",
      "Trainable params: 2,605,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_1 to have shape (6198,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-d90501e5acc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_1 to have shape (6198,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import keras.utils as utils\n",
    "\n",
    "input_size = 14\n",
    "rnn=Sequential()\n",
    "rnn.add(Embedding(tot_words, 100, input_length=input_size))\n",
    "rnn.add(SimpleRNN(300))\n",
    "rnn.add(Dropout(0.2))\n",
    "rnn.add(Dense(tot_words, activation='softmax'))\n",
    "\n",
    "print(rnn.summary())\n",
    "\n",
    "rnn.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "rnn.fit(predictors, label, batch_size=1024, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicated Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(\"i am\", 4, 15, rnn))\n",
    "print(generate_text(\"this is\", 9, 15, rnn))\n",
    "print(generate_text(\"why this\", 5, 15, rnn))\n",
    "print(generate_text(\"obama\", 7, 15, rnn))\n",
    "print(generate_text(\"she can't\", 6, 15, rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67767, 15)\n",
      "('Test score: ', 8.730955104635646)\n",
      "('Test accuracy: ', 4.426933463190048e-05)\n",
      "('Perplexity ', 6191.6389510813815)\n"
     ]
    }
   ],
   "source": [
    "output_sequences = []\n",
    "for line in test_data:\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        output_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in output_sequences])\n",
    "output_sequences = np.array(pad_sequences(output_sequences,   \n",
    "                          maxlen=15, padding='pre'))\n",
    "\n",
    "print(output_sequences.shape)\n",
    "x_test, y_test = output_sequences[:,:-1],output_sequences[:,-1]\n",
    "y_test = utils.to_categorical(y_test, num_classes=tot_words)\n",
    "\n",
    "score = rnn.evaluate(x_test, y_test, verbose=False) \n",
    "print('Test score: ', score[0])    \n",
    "print('Test accuracy: ', score[1])\n",
    "print(\"Perplexity \", np.exp(score[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 14, 50)            309900    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300)               421200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6198)              1865598   \n",
      "=================================================================\n",
      "Total params: 2,596,698\n",
      "Trainable params: 2,596,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have shape (6198,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-49eabc54bfdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/manas/.local/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have shape (6198,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "input_len = 14\n",
    "lstm=Sequential()\n",
    "lstm.add(Embedding(tot_words, 50, input_length=input_len))\n",
    "lstm.add(LSTM(300))\n",
    "lstm.add(Dense(tot_words, activation='softmax'))\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "lstm.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "lstm.fit(predictors, label, batch_size=1024, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(\"i don't\", 11, 15, model))\n",
    "print(generate_text(\"how\", 9, 15, model))\n",
    "print(generate_text(\"that was\", 6, 15, model))\n",
    "print(generate_text(\"trump\", 6, 15, model))\n",
    "print(generate_text(\"he\", 7, 15, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_sequences = []\n",
    "for line in test_data:\n",
    "    token_list=tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        output_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in output_sequences])\n",
    "output_sequences = np.array(pad_sequences(output_sequences,   \n",
    "                          maxlen=15, padding='pre'))\n",
    "\n",
    "x_test, y_test = output_sequences[:,:-1],output_sequences[:,-1]\n",
    "y_test = utils.to_categorical(y_test, num_classes=tot_words)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=False)\n",
    "print('Test score: ', score[0])    \n",
    "print('Test accuracy: ', score[1])\n",
    "print(\"Perplexity \", np.exp(score[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does Neural performs better than Classical, if so, why?\n",
    "\n",
    "Yes, the neural network perfroms better than calssical.\n",
    "The output of classical is highly reprititive. With neural networks trained at higher epochs,\n",
    "the lesser are the amount of repititions. However, grammatically,\n",
    "neural networks take more data and time to attain perfection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
